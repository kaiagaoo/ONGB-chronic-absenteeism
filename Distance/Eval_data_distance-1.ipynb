{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ee2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (79460, 143)\n",
      "Address columns built.\n",
      "Geocoding 67990 new addresses (cached: 0)...\n",
      "  0/67990 done...\n",
      "  100/67990 done...\n",
      "  200/67990 done...\n",
      "  300/67990 done...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 107\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    106\u001b[0m address_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschool_full_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m years] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhome_full_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m years]\n\u001b[0;32m--> 107\u001b[0m cache \u001b[38;5;241m=\u001b[39m geocode_unique_addresses(df, address_cols)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# -- 4. ATTACH LAT/LON --------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    110\u001b[0m addr2lat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m], cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[2], line 92\u001b[0m, in \u001b[0;36mgeocode_unique_addresses\u001b[0;34m(df, address_cols, cache_path, min_delay_seconds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m addr \u001b[38;5;129;01min\u001b[39;00m cache_map:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m loc \u001b[38;5;241m=\u001b[39m geocode(addr)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loc:\n\u001b[1;32m     94\u001b[0m     new_rows\u001b[38;5;241m.\u001b[39mappend((addr, loc\u001b[38;5;241m.\u001b[39mlatitude, loc\u001b[38;5;241m.\u001b[39mlongitude))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/geopy/extra/rate_limiter.py:274\u001b[0m, in \u001b[0;36mRateLimiter.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire_request_slot()\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(res):\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn async awaitable has been passed to `RateLimiter`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `AsyncRateLimiter` instead, which supports awaitables.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/geopy/geocoders/nominatim.py:297\u001b[0m, in \u001b[0;36mNominatim.geocode\u001b[0;34m(self, query, exactly_one, timeout, limit, addressdetails, language, geometry, extratags, country_codes, viewbox, bounded, featuretype, namedetails)\u001b[0m\n\u001b[1;32m    295\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.geocode: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, url)\n\u001b[1;32m    296\u001b[0m callback \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_json, exactly_one\u001b[38;5;241m=\u001b[39mexactly_one)\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_geocoder(url, callback, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/geopy/geocoders/base.py:368\u001b[0m, in \u001b[0;36mGeocoder._call_geocoder\u001b[0;34m(self, url, callback, timeout, is_json, headers)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_json:\n\u001b[0;32m--> 368\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter\u001b[38;5;241m.\u001b[39mget_json(url, timeout\u001b[38;5;241m=\u001b[39mtimeout, headers\u001b[38;5;241m=\u001b[39mreq_headers)\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter\u001b[38;5;241m.\u001b[39mget_text(url, timeout\u001b[38;5;241m=\u001b[39mtimeout, headers\u001b[38;5;241m=\u001b[39mreq_headers)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/geopy/adapters.py:472\u001b[0m, in \u001b[0;36mRequestsAdapter.get_json\u001b[0;34m(self, url, timeout, headers)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;241m*\u001b[39m, timeout, headers):\n\u001b[0;32m--> 472\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(url, timeout\u001b[38;5;241m=\u001b[39mtimeout, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/geopy/adapters.py:482\u001b[0m, in \u001b[0;36mRequestsAdapter._request\u001b[0;34m(self, url, timeout, headers)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;241m*\u001b[39m, timeout, headers):\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 482\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mget(url, timeout\u001b[38;5;241m=\u001b[39mtimeout, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    484\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(error)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    788\u001b[0m     conn,\n\u001b[1;32m    789\u001b[0m     method,\n\u001b[1;32m    790\u001b[0m     url,\n\u001b[1;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    800\u001b[0m )\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/urllib3/connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/http/client.py:1430\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1430\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1432\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/socket.py:719\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot read from timed out object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/ssl.py:1304\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1301\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1303\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/ssl.py:1138\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import re\n",
    "\n",
    "# -- 1. LOAD ------------------------------------------------------------------\n",
    "zip_cols = [\n",
    "    \"Zip_1718\", \"Zip_1718.1\", \"Zip_1819\", \"Zip_1819.1\",\n",
    "    \"Zip_1920\", \"Zip_1920.1\", \"Zip_2021\", \"Zip_2021.1\",\n",
    "    \"Zip_2122\", \"Zip_2122.1\", \"Zip_2223\", \"Zip_2223.1\",\n",
    "    \"Zip_2324\", \"Zip_2324.1\",\n",
    "]\n",
    "dtype_map = {c: \"string\" for c in zip_cols}\n",
    "df = pd.read_csv(\"ONGB_EvalData_CLEANED.csv\", dtype=dtype_map, low_memory=False)\n",
    "print(f\"Loaded: {df.shape}\")\n",
    "\n",
    "# -- 2. BUILD ADDRESS STRINGS -------------------------------------------------\n",
    "def build_full_address(addr, city, zipc, state=None):\n",
    "    parts = []\n",
    "    for p in [addr, city]:\n",
    "        if p is None or pd.isna(p):\n",
    "            continue\n",
    "        s = str(p).strip()\n",
    "        if s and s.lower() != \"nan\":\n",
    "            parts.append(s)\n",
    "    if zipc is not None and not pd.isna(zipc):\n",
    "        z = str(zipc).strip()\n",
    "        if z.lower() != \"nan\" and z != \"\":\n",
    "            z = re.sub(r\"\\.0\\b\", \"\", z)\n",
    "            z = re.sub(r\"[^0-9\\-]\", \"\", z)\n",
    "            if z:\n",
    "                parts.append(z)\n",
    "    if not parts:\n",
    "        return None\n",
    "    full = \", \".join(parts)\n",
    "    if state:\n",
    "        full = f\"{full}, {state}\"\n",
    "    return full\n",
    "\n",
    "years = [\"1718\", \"1819\", \"1920\", \"2021\", \"2122\", \"2223\", \"2324\"]\n",
    "\n",
    "school_cols = {\"addr\": \"School Address_{y}\", \"city\": \"City_{y}\", \"zip\": \"Zip_{y}\"}\n",
    "home_cols   = {\"addr\": \"Address_{y}\", \"city\": \"City_{y}.1\", \"zip\": \"Zip_{y}.1\"}\n",
    "\n",
    "for y in years:\n",
    "    df[f\"school_full_{y}\"] = df.apply(\n",
    "        lambda x: build_full_address(\n",
    "            x.get(school_cols[\"addr\"].format(y=y)),\n",
    "            x.get(school_cols[\"city\"].format(y=y)),\n",
    "            x.get(school_cols[\"zip\"].format(y=y)),\n",
    "            state=\"CA\"\n",
    "        ), axis=1)\n",
    "    df[f\"home_full_{y}\"] = df.apply(\n",
    "        lambda x: build_full_address(\n",
    "            x.get(home_cols[\"addr\"].format(y=y)),\n",
    "            x.get(home_cols[\"city\"].format(y=y)),\n",
    "            x.get(home_cols[\"zip\"].format(y=y)),\n",
    "            state=\"CA\"\n",
    "        ), axis=1)\n",
    "\n",
    "print(\"Address columns built.\")\n",
    "\n",
    "# -- 3. GEOCODE (with caching) ------------------------------------------------\n",
    "def load_cache(cache_path):\n",
    "    try:\n",
    "        cache = pd.read_csv(cache_path)\n",
    "        return cache.drop_duplicates(subset=[\"address\"])\n",
    "    except FileNotFoundError:\n",
    "        return pd.DataFrame(columns=[\"address\", \"lat\", \"lon\"])\n",
    "\n",
    "def save_cache(cache, cache_path):\n",
    "    cache.drop_duplicates(subset=[\"address\"]).to_csv(cache_path, index=False)\n",
    "\n",
    "def geocode_unique_addresses(df, address_cols, cache_path=\"geocode_cache.csv\", min_delay_seconds=1.0):\n",
    "    cache = load_cache(cache_path)\n",
    "    cache_map = dict(zip(cache[\"address\"], zip(cache[\"lat\"], cache[\"lon\"])))\n",
    "    unique_addrs = pd.Series(pd.unique(df[address_cols].values.ravel(\"K\"))).dropna()\n",
    "    unique_addrs = [a for a in unique_addrs if str(a).strip() and str(a).lower() != \"nan\"]\n",
    "\n",
    "    geolocator = Nominatim(user_agent=\"ongb_distance\")\n",
    "    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=min_delay_seconds)\n",
    "\n",
    "    new_rows = []\n",
    "    total = len([a for a in unique_addrs if a not in cache_map])\n",
    "    print(f\"Geocoding {total} new addresses (cached: {len(cache_map)})...\")\n",
    "\n",
    "    for i, addr in enumerate(unique_addrs):\n",
    "        if addr in cache_map:\n",
    "            continue\n",
    "        loc = geocode(addr)\n",
    "        if loc:\n",
    "            new_rows.append((addr, loc.latitude, loc.longitude))\n",
    "        else:\n",
    "            new_rows.append((addr, np.nan, np.nan))\n",
    "        if i % 100 == 0:\n",
    "            print(f\"  {i}/{total} done...\")\n",
    "\n",
    "    if new_rows:\n",
    "        cache = pd.concat([cache, pd.DataFrame(new_rows, columns=[\"address\", \"lat\", \"lon\"])], ignore_index=True)\n",
    "        save_cache(cache, cache_path)\n",
    "\n",
    "    return cache.drop_duplicates(subset=[\"address\"])\n",
    "\n",
    "address_cols = [f\"school_full_{y}\" for y in years] + [f\"home_full_{y}\" for y in years]\n",
    "cache = geocode_unique_addresses(df, address_cols)\n",
    "\n",
    "# -- 4. ATTACH LAT/LON --------------------------------------------------------\n",
    "addr2lat = dict(zip(cache[\"address\"], cache[\"lat\"]))\n",
    "addr2lon = dict(zip(cache[\"address\"], cache[\"lon\"]))\n",
    "\n",
    "for y in years:\n",
    "    df[f\"school_lat_{y}\"] = df[f\"school_full_{y}\"].map(addr2lat)\n",
    "    df[f\"school_lon_{y}\"] = df[f\"school_full_{y}\"].map(addr2lon)\n",
    "    df[f\"home_lat_{y}\"]   = df[f\"home_full_{y}\"].map(addr2lat)\n",
    "    df[f\"home_lon_{y}\"]   = df[f\"home_full_{y}\"].map(addr2lon)\n",
    "\n",
    "# -- 5. COMPUTE DISTANCES -----------------------------------------------------\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    if any(pd.isna(v) for v in [lat1, lon1, lat2, lon2]):\n",
    "        return np.nan\n",
    "    R = 6371.0\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [float(lat1), float(lon1), float(lat2), float(lon2)])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    return R * 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "for y in years:\n",
    "    df[f\"dist_km_{y}\"] = df.apply(\n",
    "        lambda x: haversine_km(\n",
    "            x.get(f\"home_lat_{y}\"), x.get(f\"home_lon_{y}\"),\n",
    "            x.get(f\"school_lat_{y}\"), x.get(f\"school_lon_{y}\")\n",
    "        ), axis=1)\n",
    "\n",
    "# -- 6. QC + SAVE -------------------------------------------------------------\n",
    "print(\"\\n=== Distance QC by Year ===\")\n",
    "for y in years:\n",
    "    s = df[f\"dist_km_{y}\"]\n",
    "    print(f\"{y}  missing: {s.isna().mean():.1%}  median: {s.median():.2f}km  max: {s.max():.1f}km\")\n",
    "\n",
    "df.to_csv(\"ONGB_with_distances.csv\", index=False)\n",
    "print(\"\\nSaved to ONGB_with_distances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0062c65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (79460, 143)\n",
      "Unique addresses: 67980\n",
      "Submitting batch 1 (9999 addresses)...\n",
      "  Batch 1 done. Matched so far: 9836\n",
      "Submitting batch 2 (9999 addresses)...\n",
      "  Batch 2 done. Matched so far: 19688\n",
      "Submitting batch 3 (9999 addresses)...\n",
      "  Batch 3 done. Matched so far: 29555\n",
      "Submitting batch 4 (9999 addresses)...\n",
      "  Batch 4 done. Matched so far: 39304\n",
      "Submitting batch 5 (9999 addresses)...\n",
      "  Batch 5 done. Matched so far: 49046\n",
      "Submitting batch 6 (9999 addresses)...\n",
      "  Batch 6 done. Matched so far: 58799\n",
      "Submitting batch 7 (7986 addresses)...\n",
      "  Batch 7 done. Matched so far: 66613\n",
      "\n",
      "Total geocoded: 67943 | Matched: 66613 | Match rate: 98.0%\n",
      "Attaching 1718...\n",
      "Attaching 1819...\n",
      "Attaching 1920...\n",
      "Attaching 2021...\n",
      "Attaching 2122...\n",
      "Attaching 2223...\n",
      "Attaching 2324...\n",
      "\n",
      "Computing distances...\n",
      "\n",
      "=== Distance QC by Year ===\n",
      "1718  missing: 52.2%  median: 1.68km  max: 4312.1km\n",
      "1819  missing: 52.6%  median: 1.68km  max: 1120.1km\n",
      "1920  missing: 53.5%  median: 1.68km  max: 4023.7km\n",
      "2021  missing: 55.2%  median: 1.70km  max: 4310.1km\n",
      "2122  missing: 55.2%  median: 1.77km  max: 3411.7km\n",
      "2223  missing: 55.8%  median: 1.73km  max: 4115.6km\n",
      "2324  missing: 55.8%  median: 1.73km  max: 4115.6km\n",
      "\n",
      "Saved to ONGB_with_distances.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "def clean_zip(zipc):\n",
    "    if zipc is None or pd.isna(zipc):\n",
    "        return \"\"\n",
    "    z = str(zipc).strip()\n",
    "    z = re.sub(r\"\\.0\\b\", \"\", z)\n",
    "    z = re.sub(r\"[^0-9\\-]\", \"\", z)\n",
    "    return z\n",
    "\n",
    "# -- LOAD DATA ----------------------------------------------------------------\n",
    "zip_cols = [\n",
    "    \"Zip_1718\", \"Zip_1718.1\", \"Zip_1819\", \"Zip_1819.1\",\n",
    "    \"Zip_1920\", \"Zip_1920.1\", \"Zip_2021\", \"Zip_2021.1\",\n",
    "    \"Zip_2122\", \"Zip_2122.1\", \"Zip_2223\", \"Zip_2223.1\",\n",
    "    \"Zip_2324\", \"Zip_2324.1\",\n",
    "]\n",
    "dtype_map = {c: \"string\" for c in zip_cols}\n",
    "df = pd.read_csv(\"ONGB_EvalData_CLEANED.csv\", dtype=dtype_map, low_memory=False)\n",
    "print(f\"Loaded: {df.shape}\")\n",
    "\n",
    "# -- COLLECT UNIQUE ADDRESSES -------------------------------------------------\n",
    "years = [\"1718\", \"1819\", \"1920\", \"2021\", \"2122\", \"2223\", \"2324\"]\n",
    "all_addresses = {}\n",
    "\n",
    "for y in years:\n",
    "    for addr_col, city_col, zip_col in [\n",
    "        (f\"School Address_{y}\", f\"City_{y}\", f\"Zip_{y}\"),\n",
    "        (f\"Address_{y}\", f\"City_{y}.1\", f\"Zip_{y}.1\"),\n",
    "    ]:\n",
    "        if addr_col not in df.columns:\n",
    "            continue\n",
    "        for _, row in df[[addr_col, city_col, zip_col]].drop_duplicates().iterrows():\n",
    "            addr = str(row[addr_col]).strip() if pd.notna(row[addr_col]) else \"\"\n",
    "            city = str(row[city_col]).strip() if pd.notna(row[city_col]) else \"\"\n",
    "            zipc = clean_zip(row[zip_col])\n",
    "            if addr and addr.lower() != \"nan\":\n",
    "                key = f\"{addr}|{city}|{zipc}\"\n",
    "                all_addresses[key] = (addr, city, zipc)\n",
    "\n",
    "print(f\"Unique addresses: {len(all_addresses)}\")\n",
    "\n",
    "# -- GEOCODE WITH FIXED PARSER ------------------------------------------------\n",
    "def parse_census_response(response_text, batch_keys):\n",
    "    results = {}\n",
    "    for line in response_text.strip().split(\"\\n\"):\n",
    "        # Remove surrounding quotes and split\n",
    "        line = line.strip().strip('\"')\n",
    "        # Use regex to parse the quoted CSV fields\n",
    "        parts = re.findall(r'\"([^\"]*)\"', response_text.split(\"\\n\")[0])\n",
    "        # Better: split the raw line properly\n",
    "        parts = re.split(r',(?=\"|\\d)', line)\n",
    "        parts = [p.strip().strip('\"') for p in parts]\n",
    "        \n",
    "        try:\n",
    "            idx = int(parts[0])\n",
    "            match_status = parts[2] if len(parts) > 2 else \"\"\n",
    "            if match_status in (\"Match\", \"Tie\") and len(parts) >= 6:\n",
    "                # coordinates field is \"lon,lat\"\n",
    "                coords = parts[5].strip().strip('\"')\n",
    "                lon_str, lat_str = coords.split(\",\")\n",
    "                lat = float(lat_str.strip())\n",
    "                lon = float(lon_str.strip())\n",
    "                results[batch_keys[idx]] = (lat, lon)\n",
    "            else:\n",
    "                results[batch_keys[idx]] = (np.nan, np.nan)\n",
    "        except (ValueError, IndexError):\n",
    "            continue\n",
    "    return results\n",
    "\n",
    "def geocode_all(addresses, cache_path=\"geocode_cache2.csv\"):\n",
    "    # Fresh cache with correct parsing\n",
    "    cache = {}\n",
    "    keys = list(addresses.keys())\n",
    "    BATCH_SIZE = 9999\n",
    "\n",
    "    for batch_start in range(0, len(keys), BATCH_SIZE):\n",
    "        batch_keys = keys[batch_start:batch_start + BATCH_SIZE]\n",
    "        batch_num = batch_start // BATCH_SIZE + 1\n",
    "        print(f\"Submitting batch {batch_num} ({len(batch_keys)} addresses)...\")\n",
    "\n",
    "        rows = []\n",
    "        for i, k in enumerate(batch_keys):\n",
    "            street, city, zipc = addresses[k]\n",
    "            rows.append(f'{i},\"{street}\",\"{city}\",\"CA\",\"{zipc}\"')\n",
    "        csv_content = \"\\n\".join(rows)\n",
    "\n",
    "        response = requests.post(\n",
    "            \"https://geocoding.geo.census.gov/geocoder/locations/addressbatch\",\n",
    "            files={\"addressFile\": (\"addresses.csv\", csv_content, \"text/csv\")},\n",
    "            data={\"benchmark\": \"Public_AR_Current\"},\n",
    "            timeout=300\n",
    "        )\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"  Batch {batch_num} failed: {response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        # Parse each line correctly\n",
    "        for line in response.text.strip().split(\"\\n\"):\n",
    "            try:\n",
    "                parts = re.findall(r'\"([^\"]*)\"', line)\n",
    "                idx = int(parts[0])\n",
    "                match_status = parts[2] if len(parts) > 2 else \"\"\n",
    "                if match_status in (\"Match\", \"Tie\"):\n",
    "                    coords = parts[5]\n",
    "                    lon_str, lat_str = coords.split(\",\")\n",
    "                    cache[batch_keys[idx]] = (float(lat_str.strip()), float(lon_str.strip()))\n",
    "                else:\n",
    "                    cache[batch_keys[idx]] = (np.nan, np.nan)\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "\n",
    "        matched = sum(1 for v in cache.values() if not np.isnan(v[0]))\n",
    "        print(f\"  Batch {batch_num} done. Matched so far: {matched}\")\n",
    "\n",
    "        # Save after each batch\n",
    "        pd.DataFrame(\n",
    "            [{\"key\": k, \"lat\": v[0], \"lon\": v[1]} for k, v in cache.items()]\n",
    "        ).to_csv(cache_path, index=False)\n",
    "\n",
    "    return cache\n",
    "\n",
    "cache = geocode_all(all_addresses)\n",
    "matched = sum(1 for v in cache.values() if not np.isnan(v[0]))\n",
    "print(f\"\\nTotal geocoded: {len(cache)} | Matched: {matched} | Match rate: {matched/len(cache):.1%}\")\n",
    "\n",
    "# -- ATTACH LAT/LON -----------------------------------------------------------\n",
    "for y in years:\n",
    "    print(f\"Attaching {y}...\")\n",
    "    for prefix, addr_col, city_col, zip_col in [\n",
    "        (\"school\", f\"School Address_{y}\", f\"City_{y}\", f\"Zip_{y}\"),\n",
    "        (\"home\",   f\"Address_{y}\",        f\"City_{y}.1\", f\"Zip_{y}.1\"),\n",
    "    ]:\n",
    "        def get_latlon(row):\n",
    "            addr = str(row.get(addr_col, \"\")).strip()\n",
    "            city = str(row.get(city_col, \"\")).strip()\n",
    "            zipc = clean_zip(row.get(zip_col, \"\"))\n",
    "            if not addr or addr.lower() == \"nan\":\n",
    "                return pd.Series([np.nan, np.nan])\n",
    "            key = f\"{addr}|{city}|{zipc}\"\n",
    "            lat, lon = cache.get(key, (np.nan, np.nan))\n",
    "            return pd.Series([lat, lon])\n",
    "\n",
    "        df[[f\"{prefix}_lat_{y}\", f\"{prefix}_lon_{y}\"]] = df.apply(get_latlon, axis=1)\n",
    "\n",
    "# -- COMPUTE DISTANCES --------------------------------------------------------\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    if any(pd.isna(v) for v in [lat1, lon1, lat2, lon2]):\n",
    "        return np.nan\n",
    "    R = 6371.0\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [float(lat1), float(lon1), float(lat2), float(lon2)])\n",
    "    dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*sin(dlon/2)**2\n",
    "    return R * 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "\n",
    "print(\"\\nComputing distances...\")\n",
    "for y in years:\n",
    "    df[f\"dist_km_{y}\"] = df.apply(\n",
    "        lambda x: haversine_km(\n",
    "            x.get(f\"home_lat_{y}\"), x.get(f\"home_lon_{y}\"),\n",
    "            x.get(f\"school_lat_{y}\"), x.get(f\"school_lon_{y}\")\n",
    "        ), axis=1)\n",
    "\n",
    "# -- QC + SAVE ----------------------------------------------------------------\n",
    "print(\"\\n=== Distance QC by Year ===\")\n",
    "for y in years:\n",
    "    s = df[f\"dist_km_{y}\"]\n",
    "    print(f\"{y}  missing: {s.isna().mean():.1%}  median: {s.median():.2f}km  max: {s.max():.1f}km\")\n",
    "\n",
    "df.to_csv(\"ONGB_with_distances.csv\", index=False)\n",
    "print(\"\\nSaved to ONGB_with_distances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd8e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quianacan/Desktop/Anderson, Quiana ONGB|Capstone\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.path.exists(\"ONGB_with_distances.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
