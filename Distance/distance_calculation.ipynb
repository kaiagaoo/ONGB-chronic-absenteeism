{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5825c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572bbdd7",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_cols = [\n",
    "    \"Zip_1718\", \"Zip_1718.1\",\n",
    "    \"Zip_1819\", \"Zip_1819.1\",\n",
    "    \"Zip_1920\", \"Zip_1920.1\",\n",
    "    \"Zip_2021\", \"Zip_2021.1\",\n",
    "    \"Zip_2122\", \"Zip_2122.1\",\n",
    "    \"Zip_2223\", \"Zip_2223.1\",\n",
    "    \"Zip_2324\", \"Zip_2324.1\",\n",
    "]\n",
    "\n",
    "dtype_map = {c: \"string\" for c in zip_cols}\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"Test1.csv\",\n",
    "    dtype=dtype_map,\n",
    "    low_memory=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"debug_full_df.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e68929",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fe5648",
   "metadata": {},
   "source": [
    "# Build full address strings (wide format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514fd040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def build_full_address(addr, city, zipc, state=None):\n",
    "    \"\"\"\n",
    "    Build a full address string from address + city + cleaned ZIP (+ optional state).\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "\n",
    "    # Address and city: treat as free text\n",
    "    for p in [addr, city]:\n",
    "        if p is None or pd.isna(p):\n",
    "            continue\n",
    "        s = str(p).strip()\n",
    "        if s and s.lower() != \"nan\":\n",
    "            parts.append(s)\n",
    "\n",
    "    # ZIP: treat as a code, not free text\n",
    "    if zipc is not None and not pd.isna(zipc):\n",
    "        z = str(zipc).strip()\n",
    "        if z.lower() != \"nan\" and z != \"\":\n",
    "            # Remove trailing '.0' if present\n",
    "            z = re.sub(r\"\\.0\\b\", \"\", z)\n",
    "            # Keep only digits and dash (ZIP or ZIP+4)\n",
    "            z = re.sub(r\"[^0-9\\-]\", \"\", z)\n",
    "            if z:\n",
    "                parts.append(z)\n",
    "\n",
    "    if not parts:\n",
    "        return None\n",
    "\n",
    "    full = \", \".join(parts)\n",
    "    if state:\n",
    "        full = f\"{full}, {state}\"\n",
    "\n",
    "    return full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "tests = [\n",
    "    # normal cases\n",
    "    (\"4521 Webster St\", \"Oakland\", \"94609\"),\n",
    "    (\"4521 Webster St\", \"Oakland\", 94609),\n",
    "    (\"4521 Webster St\", \"Oakland\", 94609.0),\n",
    "    (\"4521 Webster St\", \"Oakland\", \"94609.0\"),\n",
    "\n",
    "    # missing zip\n",
    "    (\"4521 Webster St\", \"Oakland\", None),\n",
    "    (\"4521 Webster St\", \"Oakland\", float(\"nan\")),\n",
    "\n",
    "    # zip+4\n",
    "    (\"4521 Webster St\", \"Oakland\", \"94609-1234\"),\n",
    "\n",
    "    # messy zip\n",
    "    (\"4521 Webster St\", \"Oakland\", \" 94609.0 \"),\n",
    "]\n",
    "\n",
    "for t in tests:\n",
    "    print(t, \"->\", build_full_address(*t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd6d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_full_address_columns_wide(\n",
    "    df: pd.DataFrame,\n",
    "    years: list[str],\n",
    "    school_cols: dict,  # {\"addr\":\"School Address_{y}\", \"city\":\"City_{y}\", \"zip\":\"Zip_{y}\"}\n",
    "    home_cols: dict,    # {\"addr\":\"Address_{y}\", \"city\":\"City_{y}.1\", \"zip\":\"Zip_{y}.1\"}\n",
    "    state: str | None = None,\n",
    "    school_prefix: str = \"school_full_\",\n",
    "    home_prefix: str = \"home_full_\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add full address columns for each year in a wide table:\n",
    "    school_full_{year} and home_full_{year}.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    for y in years:\n",
    "        df[f\"{school_prefix}{y}\"] = df.apply(\n",
    "            lambda x: build_full_address(\n",
    "                x.get(school_cols[\"addr\"].format(y=y)),\n",
    "                x.get(school_cols[\"city\"].format(y=y)),\n",
    "                x.get(school_cols[\"zip\"].format(y=y)),\n",
    "                state=state,\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        df[f\"{home_prefix}{y}\"] = df.apply(\n",
    "            lambda x: build_full_address(\n",
    "                x.get(home_cols[\"addr\"].format(y=y)),\n",
    "                x.get(home_cols[\"city\"].format(y=y)),\n",
    "                x.get(home_cols[\"zip\"].format(y=y)),\n",
    "                state=state,\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3906a28",
   "metadata": {},
   "source": [
    "# Geocode unique addresses with caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a818a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cache(cache_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load geocoding cache from disk.\n",
    "    Expected columns: address, lat, lon\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cache = pd.read_csv(cache_path)\n",
    "        return cache.drop_duplicates(subset=[\"address\"])\n",
    "    except FileNotFoundError:\n",
    "        return pd.DataFrame(columns=[\"address\", \"lat\", \"lon\"])\n",
    "\n",
    "\n",
    "def save_cache(cache: pd.DataFrame, cache_path: str) -> None:\n",
    "    \"\"\"Save geocoding cache to disk.\"\"\"\n",
    "    cache.drop_duplicates(subset=[\"address\"]).to_csv(cache_path, index=False)\n",
    "\n",
    "\n",
    "def geocode_unique_addresses(\n",
    "    df: pd.DataFrame,\n",
    "    address_cols: list[str],\n",
    "    cache_path: str = \"geocode_cache.csv\",\n",
    "    min_delay_seconds: float = 1.0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Geocode only unique addresses across all specified columns.\n",
    "    Results are cached to avoid repeated API calls.\n",
    "    \"\"\"\n",
    "    cache = load_cache(cache_path)\n",
    "    cache_map = dict(zip(cache[\"address\"], zip(cache[\"lat\"], cache[\"lon\"])))\n",
    "\n",
    "    # Collect unique non-missing addresses\n",
    "    unique_addrs = pd.Series(pd.unique(df[address_cols].values.ravel(\"K\"))).dropna()\n",
    "    unique_addrs = [\n",
    "        a for a in unique_addrs\n",
    "        if str(a).strip() and str(a).lower() != \"nan\"\n",
    "    ]\n",
    "\n",
    "    geolocator = Nominatim(user_agent=\"wide_table_distance\")\n",
    "    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=min_delay_seconds)\n",
    "\n",
    "    new_rows = []\n",
    "    for addr in unique_addrs:\n",
    "        if addr in cache_map:\n",
    "            continue\n",
    "\n",
    "        loc = geocode(addr)\n",
    "        if loc:\n",
    "            new_rows.append((addr, loc.latitude, loc.longitude))\n",
    "        else:\n",
    "            new_rows.append((addr, np.nan, np.nan))\n",
    "\n",
    "    if new_rows:\n",
    "        cache = pd.concat(\n",
    "            [cache, pd.DataFrame(new_rows, columns=[\"address\", \"lat\", \"lon\"])],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        save_cache(cache, cache_path)\n",
    "\n",
    "    return cache.drop_duplicates(subset=[\"address\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ce2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_latlon_wide(\n",
    "    df: pd.DataFrame,\n",
    "    years: list[str],\n",
    "    cache: pd.DataFrame,\n",
    "    school_full_prefix: str = \"school_full_\",\n",
    "    home_full_prefix: str = \"home_full_\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Map latitude and longitude from the cache back to\n",
    "    school/home address columns for each year.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    addr2lat = dict(zip(cache[\"address\"], cache[\"lat\"]))\n",
    "    addr2lon = dict(zip(cache[\"address\"], cache[\"lon\"]))\n",
    "\n",
    "    for y in years:\n",
    "        df[f\"school_lat_{y}\"] = df[f\"{school_full_prefix}{y}\"].map(addr2lat)\n",
    "        df[f\"school_lon_{y}\"] = df[f\"{school_full_prefix}{y}\"].map(addr2lon)\n",
    "        df[f\"home_lat_{y}\"]   = df[f\"{home_full_prefix}{y}\"].map(addr2lat)\n",
    "        df[f\"home_lon_{y}\"]   = df[f\"{home_full_prefix}{y}\"].map(addr2lon)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d184e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_km(lat1, lon1, lat2, lon2) -> float:\n",
    "    \"\"\"\n",
    "    Compute Haversine (great-circle) distance in kilometers.\n",
    "    \"\"\"\n",
    "    if any(pd.isna(v) for v in [lat1, lon1, lat2, lon2]):\n",
    "        return np.nan\n",
    "\n",
    "    R = 6371.0  # Earth radius in km\n",
    "    lat1, lon1, lat2, lon2 = map(\n",
    "        radians, [float(lat1), float(lon1), float(lat2), float(lon2)]\n",
    "    )\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    return R * c\n",
    "\n",
    "\n",
    "def compute_distances_wide(\n",
    "    df: pd.DataFrame,\n",
    "    years: list[str],\n",
    "    out_prefix: str = \"dist_km_\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute distance between home and school for each year\n",
    "    and store as dist_km_{year}.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    for y in years:\n",
    "        df[f\"{out_prefix}{y}\"] = df.apply(\n",
    "            lambda x: haversine_km(\n",
    "                x.get(f\"home_lat_{y}\"),\n",
    "                x.get(f\"home_lon_{y}\"),\n",
    "                x.get(f\"school_lat_{y}\"),\n",
    "                x.get(f\"school_lon_{y}\"),\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b606a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_qc(\n",
    "    df: pd.DataFrame,\n",
    "    years: list[str],\n",
    "    dist_prefix: str = \"dist_km_\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Produce basic QC statistics for distances by year:\n",
    "    missing rate and selected quantiles.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for y in years:\n",
    "        s = df[f\"{dist_prefix}{y}\"]\n",
    "        rows.append({\n",
    "            \"year\": y,\n",
    "            \"missing_rate\": float(s.isna().mean()),\n",
    "            \"p50_km\": float(s.quantile(0.50)) if s.notna().any() else np.nan,\n",
    "            \"p90_km\": float(s.quantile(0.90)) if s.notna().any() else np.nan,\n",
    "            \"p99_km\": float(s.quantile(0.99)) if s.notna().any() else np.nan,\n",
    "            \"max_km\": float(s.max()) if s.notna().any() else np.nan,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30223956",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [\"1718\", \"1819\", \"1920\", \"2021\", \"2122\", \"2223\", \"2324\"]\n",
    "\n",
    "school_cols = {\n",
    "    \"addr\": \"School Address_{y}\",\n",
    "    \"city\": \"City_{y}\",\n",
    "    \"zip\":  \"Zip_{y}\",\n",
    "}\n",
    "\n",
    "home_cols = {\n",
    "    \"addr\": \"Address_{y}\",\n",
    "    \"city\": \"City_{y}.1\",\n",
    "    \"zip\":  \"Zip_{y}.1\",\n",
    "}\n",
    "\n",
    "df = add_full_address_columns_wide(df, years, school_cols, home_cols, state=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b2e103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.school_full_1718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = \"ANON_ID\"  \n",
    "\n",
    "full_cols = [id_col] + [f\"school_full_{y}\" for y in years] + [f\"home_full_{y}\" for y in years]\n",
    "addr_df = df[full_cols].copy()\n",
    "\n",
    "addr_df.to_csv(\"addresses_full_wide.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b892492",
   "metadata": {},
   "outputs": [],
   "source": [
    "address_cols = [f\"school_full_{y}\" for y in years] + [f\"home_full_{y}\" for y in years]\n",
    "cache = geocode_unique_addresses(df, address_cols, cache_path=\"geocode_cache.csv\")\n",
    "\n",
    "df = attach_latlon_wide(df, years, cache)\n",
    "df = compute_distances_wide(df, years)\n",
    "\n",
    "qc = distance_qc(df, years)\n",
    "qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15656246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab30a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ab6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae4fda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9910fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6141945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
